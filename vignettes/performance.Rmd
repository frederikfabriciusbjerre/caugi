---
title: "Performance"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Performance}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Performance

This vignette discusses the performance characteristics of `caugi` including a comparison to the popular [`igraph`](https://r.igraph.org/), [`bnlearn`](https://www.bnlearn.com/), [`dagitty`](https://dagitty.net/), and [`ggm`](https://cran.r-project.org/web/packages/ggm/index.html).
We focus on the practical trade-offs that arise from different core data structures and design choices.

The headline is: `caugi` frontloads computation.
That is, `caugi` spends more effort when constructing a graph and preparing indexes, so that queries are wicked fast. The high performance is also due to the Rust backend.

### Design choices

#### Compressed Sparse Row (CSR) representation

The core data structure in `caugi` is a Compressed Sparse Row (CSR) representation of the graph.
CSR stores for each vertex a contiguous slice of neighbor IDs with a pointer (offset) array that marks the start/end of each slice.
This format is memory efficient for sparse graphs. The `caugi` graph object also stores important query information in the object, leading to parent, child, and neighbor queries being done in $\mathcal{O}(1)$. This yields a larger memory footprint, but the trade-off is that queries are extremely fast.

#### Mutation and lazy building

The `caugi` graph objects are expensive to build. This is the performance downside of using `caugi`. For each time, we make a modification to a `caugi` graph object, we need to rebuild the graph completely, since the graph object is immutable by design. This has complexity $\mathcal{O}(|V| + |E|)$, where $V$ is the vertex set and $E$ is the edge set. 

However, the graph object will only be rebuild, when the user either calls `build()` directly or queries the graph. Therefore, you do not need to worry about wasting compute time by iteratively making changes to a `caugi` graph object, as the graph rebuilds lazily when queried. By doing this `caugi` graphs _feel_ mutable, but, in reality, they are not. 

By doing it this way, we ensure 
- that the graph object is always in a consistent state when queried, and
- that queries are as fast as possible,
while keeping the user experience smooth.

### Comparison
#### Setup

```{r setup}
set.seed(42)
```

We are limiting ourselves to comparing graphs up to size $n = 1000$, as the conversion to `bnlearn` and `dagitty` become prohibitively slow for larger graphs.

```{r generate-graph}
generate_graphs <- function(n, p) {
  cg <- generate_graph(n = n, p = p, class = "DAG")
  ig <- as_igraph(cg)
  ggmg <- as_adjacency(cg)
  bng <- as_bnlearn(cg)
  dg <- as_dagitty(cg)
  list(cg = cg, ig = ig, ggmg = ggmg, bng = bng, dg = dg)
}
```

#### Relational queries

```{r bench-press}
graphs <- generate_graphs(1000, p = 0.25) # dense graph
cg <- graphs$cg
ig <- graphs$ig
ggmg <- graphs$ggmg
bng <- graphs$bng
dg <- graphs$dg

test_node_index <- sample.int(1000, 1)
test_node_name <- paste0("V", test_node_index)
bench::mark(
  caugi = {
    caugi::parents(cg, test_node_name)
    caugi::children(cg, test_node_name)
  },
  igraph = {
    igraph::neighbors(ig, test_node_name, mode = "in")
    igraph::neighbors(ig, test_node_name, mode = "out")
  },
  bnlearn = {
    bnlearn::parents(bng, test_node_name)
    bnlearn::children(bng, test_node_name)
  },
  ggm = {
    ggm::pa(test_node_name, ggmg)
    ggm::ch(test_node_name, ggmg)
  },
  dagitty = {
    dagitty::parents(dg, test_node_name)
    dagitty::children(dg, test_node_name)
  },
  check = FALSE # rust output are indexes, so check fails
)
```

`bnlearn` is fastest here, but is only able to handle smaller graphs, whereas `caugi` can handle very large graph objects with almost no time increase:

```{r benchmark-parents-children-large-graph}
large_cg <- generate_graph(n = 40000, m = 1000000, class = "DAG")
test_node_index <- sample.int(40000, 1)
test_node_name <- paste0("V", test_node_index)
bench::mark(
  caugi_named = {
    caugi::parents(large_cg, test_node_name)
    caugi::children(large_cg, test_node_name)
  }
)
```

For ancestors and descendants, we see that `caugi` outperforms all other packages by a large margin:

```{r an-de-an}
bench::mark(
  caugi = {
    caugi::ancestors(cg, "V500")
    caugi::descendants(cg, "V500")
  },
  bnlearn = {
    bnlearn::ancestors(bng, "V500")
    bnlearn::descendants(bng, "V500")
  },
  dagitty = {
    dagitty::ancestors(dg, "V500")
    dagitty::descendants(dg, "V500")
  },
  iterations = 10,
  check = FALSE # dagitty returns V500 as well.
)
```

#### d-separation

Using the graph from before, we obtain a valid adjustment set and then check for d-separation.

```{r benchmark-d-sep-setup}
valid_adjustment_set <- adjustment_set(cg, "V500", "V681", type = "backdoor")
valid_adjustment_set
```

```{r benchmark-d-sep}
bench::mark(
  caugi = caugi::d_separated(cg, "V500", "V681", valid_adjustment_set),
  bnlearn = bnlearn::dsep(bng, "V500", "V681", valid_adjustment_set),
  dagitty = dagitty::dseparated(dg, "V500", "V681", valid_adjustment_set),
  iterations = 10
)
```

#### Subgraph (building)

Here we see an example of where the frontloading hurts performance. When we build a subgraph, we have to rebuild the entire `caugi` graph object. Here, we see that while `caugi` outperforms other packages for queries (except for parents/children for `bnlearn`), it is slower for building the graph objects themselves, which shows for the subgraph benchmark:

```{r benchmark-subgraph}

subgraph_nodes_index <- sample.int(1000, 500)
subgraph_nodes <- paste0("V", subgraph_nodes_index)
bench::mark(
  caugi = {
    caugi::subgraph(cg, subgraph_nodes)
  },
  igraph = {
    igraph::subgraph(ig, subgraph_nodes)
  },
  bnlearn = {
    bnlearn::subgraph(bng, subgraph_nodes)
  },
  iterations = 10,
  check = FALSE
)

```


### Session info

```{r session-info}
sessionInfo()
```
